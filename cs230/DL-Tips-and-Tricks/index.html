<!DOCTYPE html>
<!-- Created by pdf2htmlEX (https://github.com/coolwanglu/pdf2htmlex) -->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta charset="utf-8"/>
<meta name="generator" content="pdf2htmlEX"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
<link rel="stylesheet" href="base.min.css"/>
<link rel="stylesheet" href="fancy.min.css"/>
<link rel="stylesheet" href="2.CS230-DL-Tips-and-Tricks.css"/>
<script>
/*
 Copyright 2012 Mozilla Foundation 
 Copyright 2013 Lu Wang <coolwanglu@gmail.com>
 Apachine License Version 2.0 
*/
(function(){function b(a,b,e,f){var c=(a.className||"").split(/\s+/g);""===c[0]&&c.shift();var d=c.indexOf(b);0>d&&e&&c.push(b);0<=d&&f&&c.splice(d,1);a.className=c.join(" ");return 0<=d}if(!("classList"in document.createElement("div"))){var e={add:function(a){b(this.element,a,!0,!1)},contains:function(a){return b(this.element,a,!1,!1)},remove:function(a){b(this.element,a,!1,!0)},toggle:function(a){b(this.element,a,!0,!0)}};Object.defineProperty(HTMLElement.prototype,"classList",{get:function(){if(this._classList)return this._classList;
var a=Object.create(e,{element:{value:this,writable:!1,enumerable:!0}});Object.defineProperty(this,"_classList",{value:a,writable:!1,enumerable:!1});return a},enumerable:!0})}})();
</script>
<script>
(function(){/*
 pdf2htmlEX.js: Core UI functions for pdf2htmlEX 
 Copyright 2012,2013 Lu Wang <coolwanglu@gmail.com> and other contributors 
 https://github.com/coolwanglu/pdf2htmlEX/blob/master/share/LICENSE 
*/
var pdf2htmlEX=window.pdf2htmlEX=window.pdf2htmlEX||{},CSS_CLASS_NAMES={page_frame:"pf",page_content_box:"pc",page_data:"pi",background_image:"bi",link:"l",input_radio:"ir",__dummy__:"no comma"},DEFAULT_CONFIG={container_id:"page-container",sidebar_id:"sidebar",outline_id:"outline",loading_indicator_cls:"loading-indicator",preload_pages:3,render_timeout:100,scale_step:0.9,key_handler:!0,hashchange_handler:!0,view_history_handler:!0,__dummy__:"no comma"},EPS=1E-6;
function invert(a){var b=a[0]*a[3]-a[1]*a[2];return[a[3]/b,-a[1]/b,-a[2]/b,a[0]/b,(a[2]*a[5]-a[3]*a[4])/b,(a[1]*a[4]-a[0]*a[5])/b]}function transform(a,b){return[a[0]*b[0]+a[2]*b[1]+a[4],a[1]*b[0]+a[3]*b[1]+a[5]]}function get_page_number(a){return parseInt(a.getAttribute("data-page-no"),16)}function disable_dragstart(a){for(var b=0,c=a.length;b<c;++b)a[b].addEventListener("dragstart",function(){return!1},!1)}
function clone_and_extend_objs(a){for(var b={},c=0,e=arguments.length;c<e;++c){var h=arguments[c],d;for(d in h)h.hasOwnProperty(d)&&(b[d]=h[d])}return b}
function Page(a){if(a){this.shown=this.loaded=!1;this.page=a;this.num=get_page_number(a);this.original_height=a.clientHeight;this.original_width=a.clientWidth;var b=a.getElementsByClassName(CSS_CLASS_NAMES.page_content_box)[0];b&&(this.content_box=b,this.original_scale=this.cur_scale=this.original_height/b.clientHeight,this.page_data=JSON.parse(a.getElementsByClassName(CSS_CLASS_NAMES.page_data)[0].getAttribute("data-data")),this.ctm=this.page_data.ctm,this.ictm=invert(this.ctm),this.loaded=!0)}}
Page.prototype={hide:function(){this.loaded&&this.shown&&(this.content_box.classList.remove("opened"),this.shown=!1)},show:function(){this.loaded&&!this.shown&&(this.content_box.classList.add("opened"),this.shown=!0)},rescale:function(a){this.cur_scale=0===a?this.original_scale:a;this.loaded&&(a=this.content_box.style,a.msTransform=a.webkitTransform=a.transform="scale("+this.cur_scale.toFixed(3)+")");a=this.page.style;a.height=this.original_height*this.cur_scale+"px";a.width=this.original_width*this.cur_scale+
"px"},view_position:function(){var a=this.page,b=a.parentNode;return[b.scrollLeft-a.offsetLeft-a.clientLeft,b.scrollTop-a.offsetTop-a.clientTop]},height:function(){return this.page.clientHeight},width:function(){return this.page.clientWidth}};function Viewer(a){this.config=clone_and_extend_objs(DEFAULT_CONFIG,0<arguments.length?a:{});this.pages_loading=[];this.init_before_loading_content();var b=this;document.addEventListener("DOMContentLoaded",function(){b.init_after_loading_content()},!1)}
Viewer.prototype={scale:1,cur_page_idx:0,first_page_idx:0,init_before_loading_content:function(){this.pre_hide_pages()},initialize_radio_button:function(){for(var a=document.getElementsByClassName(CSS_CLASS_NAMES.input_radio),b=0;b<a.length;b++)a[b].addEventListener("click",function(){this.classList.toggle("checked")})},init_after_loading_content:function(){this.sidebar=document.getElementById(this.config.sidebar_id);this.outline=document.getElementById(this.config.outline_id);this.container=document.getElementById(this.config.container_id);
this.loading_indicator=document.getElementsByClassName(this.config.loading_indicator_cls)[0];for(var a=!0,b=this.outline.childNodes,c=0,e=b.length;c<e;++c)if("ul"===b[c].nodeName.toLowerCase()){a=!1;break}a||this.sidebar.classList.add("opened");this.find_pages();if(0!=this.pages.length){disable_dragstart(document.getElementsByClassName(CSS_CLASS_NAMES.background_image));this.config.key_handler&&this.register_key_handler();var h=this;this.config.hashchange_handler&&window.addEventListener("hashchange",
function(a){h.navigate_to_dest(document.location.hash.substring(1))},!1);this.config.view_history_handler&&window.addEventListener("popstate",function(a){a.state&&h.navigate_to_dest(a.state)},!1);this.container.addEventListener("scroll",function(){h.update_page_idx();h.schedule_render(!0)},!1);[this.container,this.outline].forEach(function(a){a.addEventListener("click",h.link_handler.bind(h),!1)});this.initialize_radio_button();this.render()}},find_pages:function(){for(var a=[],b={},c=this.container.childNodes,
e=0,h=c.length;e<h;++e){var d=c[e];d.nodeType===Node.ELEMENT_NODE&&d.classList.contains(CSS_CLASS_NAMES.page_frame)&&(d=new Page(d),a.push(d),b[d.num]=a.length-1)}this.pages=a;this.page_map=b},load_page:function(a,b,c){var e=this.pages;if(!(a>=e.length||(e=e[a],e.loaded||this.pages_loading[a]))){var e=e.page,h=e.getAttribute("data-page-url");if(h){this.pages_loading[a]=!0;var d=e.getElementsByClassName(this.config.loading_indicator_cls)[0];"undefined"===typeof d&&(d=this.loading_indicator.cloneNode(!0),
d.classList.add("active"),e.appendChild(d));var f=this,g=new XMLHttpRequest;g.open("GET",h,!0);g.onload=function(){if(200===g.status||0===g.status){var b=document.createElement("div");b.innerHTML=g.responseText;for(var d=null,b=b.childNodes,e=0,h=b.length;e<h;++e){var p=b[e];if(p.nodeType===Node.ELEMENT_NODE&&p.classList.contains(CSS_CLASS_NAMES.page_frame)){d=p;break}}b=f.pages[a];f.container.replaceChild(d,b.page);b=new Page(d);f.pages[a]=b;b.hide();b.rescale(f.scale);disable_dragstart(d.getElementsByClassName(CSS_CLASS_NAMES.background_image));
f.schedule_render(!1);c&&c(b)}delete f.pages_loading[a]};g.send(null)}void 0===b&&(b=this.config.preload_pages);0<--b&&(f=this,setTimeout(function(){f.load_page(a+1,b)},0))}},pre_hide_pages:function(){var a="@media screen{."+CSS_CLASS_NAMES.page_content_box+"{display:none;}}",b=document.createElement("style");b.styleSheet?b.styleSheet.cssText=a:b.appendChild(document.createTextNode(a));document.head.appendChild(b)},render:function(){for(var a=this.container,b=a.scrollTop,c=a.clientHeight,a=b-c,b=
b+c+c,c=this.pages,e=0,h=c.length;e<h;++e){var d=c[e],f=d.page,g=f.offsetTop+f.clientTop,f=g+f.clientHeight;g<=b&&f>=a?d.loaded?d.show():this.load_page(e):d.hide()}},update_page_idx:function(){var a=this.pages,b=a.length;if(!(2>b)){for(var c=this.container,e=c.scrollTop,c=e+c.clientHeight,h=-1,d=b,f=d-h;1<f;){var g=h+Math.floor(f/2),f=a[g].page;f.offsetTop+f.clientTop+f.clientHeight>=e?d=g:h=g;f=d-h}this.first_page_idx=d;for(var g=h=this.cur_page_idx,k=0;d<b;++d){var f=a[d].page,l=f.offsetTop+f.clientTop,
f=f.clientHeight;if(l>c)break;f=(Math.min(c,l+f)-Math.max(e,l))/f;if(d===h&&Math.abs(f-1)<=EPS){g=h;break}f>k&&(k=f,g=d)}this.cur_page_idx=g}},schedule_render:function(a){if(void 0!==this.render_timer){if(!a)return;clearTimeout(this.render_timer)}var b=this;this.render_timer=setTimeout(function(){delete b.render_timer;b.render()},this.config.render_timeout)},register_key_handler:function(){var a=this;window.addEventListener("DOMMouseScroll",function(b){if(b.ctrlKey){b.preventDefault();var c=a.container,
e=c.getBoundingClientRect(),c=[b.clientX-e.left-c.clientLeft,b.clientY-e.top-c.clientTop];a.rescale(Math.pow(a.config.scale_step,b.detail),!0,c)}},!1);window.addEventListener("keydown",function(b){var c=!1,e=b.ctrlKey||b.metaKey,h=b.altKey;switch(b.keyCode){case 61:case 107:case 187:e&&(a.rescale(1/a.config.scale_step,!0),c=!0);break;case 173:case 109:case 189:e&&(a.rescale(a.config.scale_step,!0),c=!0);break;case 48:e&&(a.rescale(0,!1),c=!0);break;case 33:h?a.scroll_to(a.cur_page_idx-1):a.container.scrollTop-=
a.container.clientHeight;c=!0;break;case 34:h?a.scroll_to(a.cur_page_idx+1):a.container.scrollTop+=a.container.clientHeight;c=!0;break;case 35:a.container.scrollTop=a.container.scrollHeight;c=!0;break;case 36:a.container.scrollTop=0,c=!0}c&&b.preventDefault()},!1)},rescale:function(a,b,c){var e=this.scale;this.scale=a=0===a?1:b?e*a:a;c||(c=[0,0]);b=this.container;c[0]+=b.scrollLeft;c[1]+=b.scrollTop;for(var h=this.pages,d=h.length,f=this.first_page_idx;f<d;++f){var g=h[f].page;if(g.offsetTop+g.clientTop>=
c[1])break}g=f-1;0>g&&(g=0);var g=h[g].page,k=g.clientWidth,f=g.clientHeight,l=g.offsetLeft+g.clientLeft,m=c[0]-l;0>m?m=0:m>k&&(m=k);k=g.offsetTop+g.clientTop;c=c[1]-k;0>c?c=0:c>f&&(c=f);for(f=0;f<d;++f)h[f].rescale(a);b.scrollLeft+=m/e*a+g.offsetLeft+g.clientLeft-m-l;b.scrollTop+=c/e*a+g.offsetTop+g.clientTop-c-k;this.schedule_render(!0)},fit_width:function(){var a=this.cur_page_idx;this.rescale(this.container.clientWidth/this.pages[a].width(),!0);this.scroll_to(a)},fit_height:function(){var a=this.cur_page_idx;
this.rescale(this.container.clientHeight/this.pages[a].height(),!0);this.scroll_to(a)},get_containing_page:function(a){for(;a;){if(a.nodeType===Node.ELEMENT_NODE&&a.classList.contains(CSS_CLASS_NAMES.page_frame)){a=get_page_number(a);var b=this.page_map;return a in b?this.pages[b[a]]:null}a=a.parentNode}return null},link_handler:function(a){var b=a.target,c=b.getAttribute("data-dest-detail");if(c){if(this.config.view_history_handler)try{var e=this.get_current_view_hash();window.history.replaceState(e,
"","#"+e);window.history.pushState(c,"","#"+c)}catch(h){}this.navigate_to_dest(c,this.get_containing_page(b));a.preventDefault()}},navigate_to_dest:function(a,b){try{var c=JSON.parse(a)}catch(e){return}if(c instanceof Array){var h=c[0],d=this.page_map;if(h in d){for(var f=d[h],h=this.pages[f],d=2,g=c.length;d<g;++d){var k=c[d];if(null!==k&&"number"!==typeof k)return}for(;6>c.length;)c.push(null);var g=b||this.pages[this.cur_page_idx],d=g.view_position(),d=transform(g.ictm,[d[0],g.height()-d[1]]),
g=this.scale,l=[0,0],m=!0,k=!1,n=this.scale;switch(c[1]){case "XYZ":l=[null===c[2]?d[0]:c[2]*n,null===c[3]?d[1]:c[3]*n];g=c[4];if(null===g||0===g)g=this.scale;k=!0;break;case "Fit":case "FitB":l=[0,0];k=!0;break;case "FitH":case "FitBH":l=[0,null===c[2]?d[1]:c[2]*n];k=!0;break;case "FitV":case "FitBV":l=[null===c[2]?d[0]:c[2]*n,0];k=!0;break;case "FitR":l=[c[2]*n,c[5]*n],m=!1,k=!0}if(k){this.rescale(g,!1);var p=this,c=function(a){l=transform(a.ctm,l);m&&(l[1]=a.height()-l[1]);p.scroll_to(f,l)};h.loaded?
c(h):(this.load_page(f,void 0,c),this.scroll_to(f))}}}},scroll_to:function(a,b){var c=this.pages;if(!(0>a||a>=c.length)){c=c[a].view_position();void 0===b&&(b=[0,0]);var e=this.container;e.scrollLeft+=b[0]-c[0];e.scrollTop+=b[1]-c[1]}},get_current_view_hash:function(){var a=[],b=this.pages[this.cur_page_idx];a.push(b.num);a.push("XYZ");var c=b.view_position(),c=transform(b.ictm,[c[0],b.height()-c[1]]);a.push(c[0]/this.scale);a.push(c[1]/this.scale);a.push(this.scale);return JSON.stringify(a)}};
pdf2htmlEX.Viewer=Viewer;})();
</script>
<script>
try{
pdf2htmlEX.defaultViewer = new pdf2htmlEX.Viewer({});
}catch(e){}
</script>
<title></title>
</head>
<body>
<div id="sidebar">
<div id="outline">
<ul><li><a class="l" href="#pf1" data-dest-detail='[1,"XYZ",154,569.5,null]'>第三部分 深度学习技巧与建议 / Deep Learning Tips and Tricks</a><ul><li><a class="l" href="#pf1" data-dest-detail='[1,"XYZ",28.35,489.8,null]'>[1] 数据预处理 / Data Processing</a><ul><li><a class="l" href="#pf1" data-dest-detail='[1,"XYZ",28.35,458.3,null]'>░▐ 数据增强</a></li><li><a class="l" href="#pf1" data-dest-detail='[1,"XYZ",421.65,489.8,null]'>░▐ 批标准化 Batch normalization</a></li></ul></li><li><a class="l" href="#pf1" data-dest-detail='[1,"XYZ",421.65,342.95,null]'>[2] 训练神经网络 / Training a Neural Network</a><ul><li><a class="l" href="#pf1" data-dest-detail='[1,"XYZ",421.65,311.4,null]'>2.1 定义 Definitions</a><ul><li><a class="l" href="#pf1" data-dest-detail='[1,"XYZ",421.65,282.3,null]'>░▐ 轮次 Epoch</a></li><li><a class="l" href="#pf1" data-dest-detail='[1,"XYZ",421.65,220.35,null]'>░▐ Mini-batch gradient descent</a></li><li><a class="l" href="#pf1" data-dest-detail='[1,"XYZ",421.65,146.4,null]'>░▐ 损失函数 Loss function</a></li><li><a class="l" href="#pf1" data-dest-detail='[1,"XYZ",421.65,99.05,null]'>░▐ 交叉熵损失函式 Cross-entropy loss</a></li></ul></li><li><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",28.35,569.5,null]'>2.2 寻找最优权重 Finding Optimal Weights</a><ul><li><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",28.35,540.4,null]'>░▐ 反向传播 Backpropagation</a></li><li><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",28.35,356.85,null]'>░▐ 更新权重 Updating weights</a></li></ul></li></ul></li><li><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",28.35,142.85,null]'>[3] 参数调优 / Parameter Tuning</a><ul><li><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",28.35,117.3,null]'>3.1 权重初始化 Weights Initialization</a><ul><li><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",28.35,94.2,null]'>░▐ 哈维尔初始化 Xavier initialization</a></li><li><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",421.65,569.5,null]'>░▐ 迁移学习 Transfer learning</a></li></ul></li><li><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",421.65,291.3,null]'>3.2 优化与收敛细节 Optimizing Convergence</a><ul><li><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",421.65,262.2,null]'>░▐ 学习率 Learning rate</a></li><li><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",421.65,200.2,null]'>░▐ 自适应学习率 Adaptive learning rates</a></li></ul></li></ul></li><li><a class="l" href="#pf3" data-dest-detail='[3,"XYZ",28.35,453,null]'>[4] 正则化 / Regularization</a><ul><li><a class="l" href="#pf3" data-dest-detail='[3,"XYZ",28.35,421.45,null]'>░▐ 随机失活 Dropout</a></li><li><a class="l" href="#pf3" data-dest-detail='[3,"XYZ",28.35,250.65,null]'>░▐ 权重正则化 Weight regularization</a></li><li><a class="l" href="#pf3" data-dest-detail='[3,"XYZ",421.65,569.5,null]'>░▐ 早停止 Early stopping</a></li></ul></li><li><a class="l" href="#pf3" data-dest-detail='[3,"XYZ",421.65,412.7,null]'>[5]实践技巧 / Good Practices</a><ul><li><a class="l" href="#pf3" data-dest-detail='[3,"XYZ",421.65,381.15,null]'>░▐ 小批量数据完全拟合测试 Overfitting small batch</a></li><li><a class="l" href="#pf3" data-dest-detail='[3,"XYZ",421.65,263.2,null]'>░▐ 梯度检查 Gradient checking</a></li></ul></li></ul></li></ul></div>
</div>
<div id="page-container">
<div id="pf1" class="pf w0 h0" data-page-no="1"><div class="pc pc1 w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="bg1.png"/><div class="t m0 x1 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">CS230<span class="_ _0"> </span><span class="ff2 fs1">|<span class="_ _1"> </span>Deep<span class="_ _1"> </span>Lear<span class="_ _2"></span>ning<span class="_ _1"> </span><span class="ff3">•<span class="_ _1"> </span></span>Stanford<span class="_ _3"> </span>University<span class="_ _4"> </span><span class="ff4">系列内容 </span>Awesome<span class="_ _3"> </span>AI<span class="_ _1"> </span>Courses<span class="_ _1"> </span>Notes<span class="_ _3"> </span>Cheat<span class="_ _1"> </span>Sheets<span class="_ _3"> </span><span class="ff4">@<span class="_ _5"> </span></span>ShowMeAI</span></div><div class="t m0 x1 h3 y2 ff4 fs1 fc0 sc0 ls0 ws0">第三部分<span class="_ _6"> </span>深度学习技巧与建议<span class="_ _6"> </span>/</div><div class="t m0 x2 h4 y3 ff5 fs1 fc0 sc0 ls0 ws0">Deep<span class="_ _6"> </span>Lear<span class="_ _7"></span>ning<span class="_ _6"> </span>Tips<span class="_ _5"> </span>and<span class="_ _6"> </span>Tricks</div><div class="c x3 y4 w2 h5"><div class="t m0 x4 h6 y5 ff1 fs1 fc0 sc0 ls0 ws0">-<span class="_ _3"> </span>1<span class="_ _1"> </span>-</div></div><div class="t m0 x5 h7 y6 ff4 fs2 fc0 sc0 ls0 ws0">第三部分<span class="_ _0"> </span>深度学习技巧与建议</div><div class="t m0 x6 h8 y7 ff2 fs2 fc0 sc0 ls0 ws0">/<span class="_ _0"> </span>Deep<span class="_ _8"> </span>Learning<span class="_ _0"> </span>Tips<span class="_ _0"> </span>a<span class="_ _7"></span>nd<span class="_ _0"> </span>Tricks</div><div class="t m0 x7 h9 y8 ff6 fs1 fc0 sc0 ls0 ws0">翻译&amp;校正<span class="_ _1"> </span>|<span class="_ _6"> </span><span class="ff4">韩信子@ShowMeAI<span class="_ _9"> </span></span>编辑<span class="_ _6"> </span>|<span class="_ _6"> </span><span class="ff4">南乔@ShowMeAI<span class="_ _9"> </span></span>原文作者<span class="_ _1"> </span>|<span class="_ _6"> </span><span class="ff7">https://stanford.edu/~shervine<span class="_ _a"> </span><span class="ff4">本节原文超链</span></span></div><div class="c x4 y9 w3 ha"><div class="t m0 x1 hb ya ff2 fs0 fc0 sc0 ls0 ws0">[1]<span class="_ _6"> </span><span class="ff8">数据预处理<span class="_ _5"> </span></span>/<span class="_ _6"> </span>Data<span class="_ _5"> </span>P<span class="_ _2"></span>rocessing</div><div class="t m0 x1 hc yb ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">数据增强</span></div><div class="t m0 x1 h9 yc ff6 fs1 fc0 sc0 ls0 ws0">深度学习模型通常需要大量数据才能正确训练。使用数据增强技术从现有数据中获取更</div><div class="t m0 x1 h9 yd ff6 fs1 fc0 sc0 ls0 ws0">多数据通常很有用。</div><div class="t m0 x1 h9 ye ff6 fs1 fc0 sc0 ls0 ws0">主要内容总结在下表中。更具体地说，对于输入图像数据，我们可以应用以下技术：</div></div><div class="c x1 yf w4 hd"><div class="t m0 x0 he y10 ff6 fs3 fc0 sc0 ls0 ws0">原始图片</div><div class="t m0 x1 hf y11 ff5 fs3 fc0 sc0 ls0 ws0">Original</div></div><div class="c x8 yf w4 hd"><div class="t m0 x9 he y10 ff6 fs3 fc0 sc0 ls0 ws0">翻转</div><div class="t m0 xa hf y11 ff5 fs3 fc0 sc0 ls0 ws0">Flip</div></div><div class="c xb yf w4 hd"><div class="t m0 x9 he y10 ff6 fs3 fc0 sc0 ls0 ws0">旋转</div><div class="t m0 x0 hf y11 ff5 fs3 fc0 sc0 ls0 ws0">Rotation</div></div><div class="c xc yf w4 hd"><div class="t m0 x0 he y10 ff6 fs3 fc0 sc0 ls0 ws0">随机截取</div><div class="t m0 xd hf y11 ff5 fs3 fc0 sc0 ls0 ws0">Random<span class="_ _6"> </span>crop</div></div><div class="c x1 y12 w4 h10"><div class="t m0 x1 he y13 ff6 fs3 fc0 sc0 ls0 ws0">原始图片</div></div><div class="c x8 y12 w4 h10"><div class="t m0 x9 he y14 ff6 fs3 fc0 sc0 ls0 ws0">翻转</div><div class="t m0 xe he y15 ff6 fs3 fc0 sc0 ls0 ws0">（保留图像含<span class="_ _7"></span>义）</div></div><div class="c xb y12 w4 h10"><div class="t m0 xf he y13 ff6 fs3 fc0 sc0 ls0 ws0">小角度旋转</div></div><div class="c xc y12 w4 h10"><div class="t m0 x10 he y16 ff6 fs3 fc0 sc0 ls0 ws0">随机聚焦图像<span class="_ _7"></span>的一个</div><div class="t m0 x9 he y14 ff6 fs3 fc0 sc0 ls0 ws0">部分</div><div class="t m0 x11 he y15 ff6 fs3 fc0 sc0 ls0 ws0">可连续进行多<span class="_ _7"></span>次随机</div><div class="t m0 x9 he y17 ff6 fs3 fc0 sc0 ls0 ws0">裁剪</div></div><div class="c x0 y18 w4 hd"><div class="t m0 x0 he y19 ff6 fs3 fc0 sc0 ls0 ws0">颜色调整</div><div class="t m0 x12 hf y1a ff5 fs3 fc0 sc0 ls0 ws0">Color<span class="_ _1"> </span>shif<span class="_ _7"></span>t</div></div><div class="c x8 y18 w4 hd"><div class="t m0 x0 he y19 ff6 fs3 fc0 sc0 ls0 ws0">添加噪声</div><div class="t m0 x13 hf y1a ff5 fs3 fc0 sc0 ls0 ws0">Noise<span class="_ _6"> </span>addition</div></div><div class="c xb y18 w4 hd"><div class="t m0 x0 he y19 ff6 fs3 fc0 sc0 ls0 ws0">信息损失</div><div class="t m0 x14 hf y1a ff5 fs3 fc0 sc0 ls0 ws0">Information<span class="_ _6"> </span>loss</div></div><div class="c xc y18 w4 hd"><div class="t m0 xf he y19 ff6 fs3 fc0 sc0 ls0 ws0">对比度变化</div><div class="t m0 x14 hf y1a ff5 fs3 fc0 sc0 ls0 ws0">Contrast<span class="_ _6"> </span>change</div></div><div class="c x0 y1b w4 h10"><div class="t m0 x10 he y1c ff5 fs3 fc0 sc0 ls0 ws0">RGB<span class="_ _1"> </span><span class="ff6">的细微差<span class="_ _7"></span>别略有</span></div><div class="t m0 x9 he y1d ff6 fs3 fc0 sc0 ls0 ws0">变化</div><div class="t m0 x10 he y1e ff6 fs3 fc0 sc0 ls0 ws0">捕捉曝光时可<span class="_ _7"></span>能出现</div><div class="t m0 x9 he y1f ff6 fs3 fc0 sc0 ls0 ws0">噪点</div></div><div class="c x8 y1b w4 h10"><div class="t m0 x0 he y20 ff6 fs3 fc0 sc0 ls0 ws0">增加噪声</div><div class="t m0 x10 he y21 ff6 fs3 fc0 sc0 ls0 ws0">对输入质量变<span class="_ _7"></span>化的容</div><div class="t m0 x0 he y22 ff6 fs3 fc0 sc0 ls0 ws0">忍度更高</div></div><div class="c xb y1b w4 h10"><div class="t m0 x15 he y20 ff6 fs3 fc0 sc0 ls0 ws0">部分图像被<span class="_ _7"></span><span class="ff5">(</span>遮挡<span class="ff5">)</span>忽略</div><div class="t m0 x10 he y21 ff6 fs3 fc0 sc0 ls0 ws0">模拟图像部分<span class="_ _7"></span>的潜在</div><div class="t m0 x9 he y22 ff6 fs3 fc0 sc0 ls0 ws0">损失</div></div><div class="c xc y1b w4 h10"><div class="t m0 x0 he y20 ff6 fs3 fc0 sc0 ls0 ws0">亮度变化</div><div class="t m0 x10 he y21 ff6 fs3 fc0 sc0 ls0 ws0">控制因一天中<span class="_ _7"></span>的时间</div><div class="t m0 xe he y22 ff6 fs3 fc0 sc0 ls0 ws0">而导致的曝光<span class="_ _7"></span>差异</div></div><div class="c x4 y9 w3 ha"><div class="t m0 x1 h9 y23 ff6 fs1 fc0 sc0 ls0 ws0">备注：数据通常在训练期间即时增强。</div></div><div class="c x6 y9 w3 ha"><div class="t m0 x0 hc y24 ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">批标准化</span></div><div class="t m0 x16 h4 y25 ff5 fs1 fc0 sc0 ls0 ws0">Batch<span class="_ _6"> </span>no<span class="_ _7"></span>rmalization</div><div class="t m0 x0 h9 y26 ff6 fs1 fc0 sc0 ls0 ws0">这个<span class="_ _7"></span>步<span class="_ _7"></span>骤<span class="_ _7"></span>通<span class="_ _7"></span>过<span class="_ _7"></span>超<span class="_ _7"></span>参数</div><div class="t m0 x17 h11 y27 ffa fs1 fc0 sc0 ls0 ws0"><span class="ff5">,<span class="_ _3"> </span></span></div><div class="t m0 x18 h9 y26 ff6 fs1 fc0 sc0 ls0 ws0">对批<span class="_ _7"></span>次</div><div class="t m0 x19 h11 y27 ff5 fs1 fc0 sc0 ls0 ws0">{<span class="ffa"></span></div><div class="t m0 x1a h12 y28 ffa fs4 fc0 sc0 ls0 ws0"></div><div class="t m0 x1b h4 y27 ff5 fs1 fc0 sc0 ls0 ws0">}</div><div class="t m0 x1c h9 y26 ff6 fs1 fc0 sc0 ls0 ws0">进行<span class="_ _7"></span>归<span class="_ _7"></span>一<span class="_ _7"></span>化<span class="_ _7"></span>。<span class="_ _7"></span>我<span class="_ _7"></span>们把<span class="_ _7"></span>想<span class="_ _7"></span>要<span class="_ _7"></span>校<span class="_ _7"></span>正<span class="_ _7"></span>的批<span class="_ _7"></span>次<span class="_ _7"></span>的<span class="_ _7"></span>均<span class="_ _7"></span>值和<span class="_ _7"></span>方</div><div class="t m0 x0 h9 y29 ff6 fs1 fc0 sc0 ls0 ws0">差记作</div><div class="t m0 x1d h11 y2a ffa fs1 fc0 sc0 ls0 ws0"></div><div class="t m0 x1e h12 y2b ffa fs4 fc0 sc0 ls0 ws0"></div><div class="t m0 x1f h11 y2a ff5 fs1 fc0 sc0 ls0 ws0">,<span class="_ _3"> </span><span class="ffa"></span></div><div class="t m0 x20 h12 y2c ffa fs4 fc0 sc0 ls0 ws0"></div><div class="t m0 x20 h13 y2d ffb fs4 fc0 sc0 ls0 ws0">2</div><div class="t m0 x21 h9 y29 ff6 fs1 fc0 sc0 ls0 ws0">，那归一化过程公式：</div><div class="t m0 x2 h14 y2e ffa fs5 fc0 sc0 ls0 ws0"></div><div class="t m0 x22 h15 y2f ffa fs6 fc0 sc0 ls0 ws0"></div><div class="t m0 x1a h14 y2e ffa fs5 fc0 sc0 ls0 ws0">←<span class="_ _5"></span></div><div class="t m0 x23 h14 y30 ffa fs5 fc0 sc0 ls0 ws0"></div><div class="t m0 x24 h15 y31 ffa fs6 fc0 sc0 ls0 ws0"></div><div class="t m0 xb h14 y30 ffa fs5 fc0 sc0 ls0 ws0">−<span class="_ _6"></span></div><div class="t m0 x25 h15 y32 ffa fs6 fc0 sc0 ls0 ws0"></div><div class="t m0 x24 h14 y33 ffa fs5 fc0 sc0 ls0 ws0"></div><div class="t m0 xb h15 y34 ffa fs6 fc0 sc0 ls0 ws0"></div><div class="t m0 xb h15 y35 ffa fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x26 h14 y33 ffa fs5 fc0 sc0 ls0 ws0">+<span class="_ _6"></span></div><div class="t m0 x27 h14 y36 ffa fs5 fc0 sc0 ls0 ws0">+<span class="_ _1"></span></div><div class="t m0 x0 h9 y37 ff5 fs1 fc0 sc0 ls0 ws0">BN<span class="_ _5"> </span><span class="ff6">通<span class="_ _7"></span>常<span class="_ _7"></span>在全<span class="_ _7"></span>连<span class="_ _7"></span>接<span class="_ _7"></span></span>/<span class="_ _7"></span><span class="ff6">卷<span class="_ _7"></span>积<span class="_ _7"></span>层之<span class="_ _7"></span>后<span class="_ _7"></span>和<span class="_ _7"></span>非<span class="_ _7"></span>线<span class="_ _7"></span>性<span class="_ _7"></span>层<span class="_ _7"></span>之<span class="_ _7"></span>前<span class="_ _7"></span>完<span class="_ _7"></span>成<span class="_ _7"></span>，<span class="_ _7"></span>旨在<span class="_ _7"></span>允<span class="_ _7"></span>许<span class="_ _7"></span>更<span class="_ _7"></span>高<span class="_ _7"></span>的<span class="_ _7"></span>学<span class="_ _7"></span>习率<span class="_ _7"></span>并<span class="_ _7"></span>减<span class="_ _7"></span>少<span class="_ _7"></span>对</span></div><div class="t m0 x0 h9 y38 ff6 fs1 fc0 sc0 ls0 ws0">初始化的依赖。</div><div class="t m0 x0 hb y39 ff2 fs0 fc0 sc0 ls0 ws0">[2]<span class="_ _6"> </span><span class="ff8">训练神经网络<span class="_ _5"> </span></span>/<span class="_ _6"> </span>Training<span class="_ _6"> </span>a<span class="_ _5"> </span>Neural<span class="_ _6"> </span>Network</div><div class="t m0 x0 h16 y3a ff5 fs7 fc0 sc0 ls0 ws0">2.1<span class="_ _5"> </span><span class="ff8">定义<span class="_ _b"> </span></span>Definitions</div><div class="t m0 x0 hc y3b ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">轮次<span class="_ _5"> </span><span class="ff5">Epoch</span></span></div><div class="t m0 x0 h9 y3c ff6 fs1 fc0 sc0 ls0 ws0">在训<span class="_ _7"></span>练<span class="_ _7"></span>模<span class="_ _7"></span>型<span class="_ _c"></span>的上<span class="_ _7"></span>下<span class="_ _7"></span>文<span class="_ _7"></span>中<span class="_ _7"></span>，<span class="_ _7"></span><span class="ff5">epoch<span class="_ _5"> </span></span>是<span class="_ _7"></span>一<span class="_ _7"></span>个<span class="_ _7"></span>术<span class="_ _7"></span>语<span class="_ _7"></span>，<span class="_ _7"></span>用<span class="_ _7"></span>于<span class="_ _7"></span>指<span class="_ _7"></span>代<span class="_ _7"></span>模型<span class="_ _7"></span>看<span class="_ _c"></span>到<span class="_ _7"></span>整<span class="_ _7"></span>个训<span class="_ _7"></span>练<span class="_ _7"></span>集<span class="_ _7"></span>一<span class="_ _7"></span>次<span class="_ _c"></span>，并</div><div class="t m0 x0 h9 y3d ff6 fs1 fc0 sc0 ls0 ws0">进行权重更新迭代。</div><div class="t m0 x0 hc y3e ff9 fs1 fc0 sc0 ls0 ws0">░▐</div><div class="t m0 x28 h4 y3f ff5 fs1 fc0 sc0 ls0 ws0">Mini-batch<span class="_ _5"> </span>gradient<span class="_ _6"> </span>descent</div><div class="t m0 x0 h9 y40 ff6 fs1 fc0 sc0 ls0 ws0">在训<span class="_ _7"></span>练<span class="_ _7"></span>阶<span class="_ _7"></span>段<span class="_ _7"></span>，<span class="_ _7"></span>由<span class="_ _7"></span>于<span class="_ _7"></span>计<span class="_ _7"></span>算<span class="_ _7"></span>复<span class="_ _7"></span>杂<span class="_ _7"></span>性<span class="_ _7"></span>或<span class="_ _7"></span>由<span class="_ _7"></span>于<span class="_ _7"></span>噪<span class="_ _7"></span>声<span class="_ _7"></span>问<span class="_ _7"></span>题<span class="_ _7"></span>，<span class="_ _7"></span>更<span class="_ _7"></span>新<span class="_ _7"></span>权<span class="_ _7"></span>重<span class="_ _7"></span>通<span class="_ _7"></span>常不<span class="_ _7"></span>是<span class="_ _7"></span>基<span class="_ _7"></span>于<span class="_ _c"></span>整个<span class="_ _7"></span>训<span class="_ _7"></span>练<span class="_ _7"></span>集<span class="_ _7"></span>一</div><div class="t m0 x0 h9 y41 ff6 fs1 fc0 sc0 ls0 ws0">次。<span class="_ _7"></span>相<span class="_ _7"></span>反，<span class="_ _7"></span>更<span class="_ _7"></span>新<span class="_ _7"></span>步骤<span class="_ _7"></span>是在<span class="_ _7"></span>小<span class="_ _7"></span>批<span class="_ _7"></span>量<span class="_ _7"></span>上完<span class="_ _7"></span>成<span class="_ _7"></span>的，<span class="_ _7"></span>其<span class="_ _7"></span>中 <span class="ff5">batch<span class="_ _5"> </span></span>批<span class="_ _7"></span>量中<span class="_ _7"></span>的<span class="_ _7"></span>数<span class="_ _7"></span>据量<span class="_ _7"></span>是<span class="_ _7"></span>我<span class="_ _7"></span>们可<span class="_ _7"></span>以<span class="_ _7"></span>调</div><div class="t m0 x0 h9 y42 ff6 fs1 fc0 sc0 ls0 ws0">整的超参数。</div><div class="t m0 x0 hc y43 ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">损失函数<span class="_ _5"> </span><span class="ff5">Loss<span class="_ _6"> </span>function</span></span></div><div class="t m0 x0 h9 y44 ff6 fs1 fc0 sc0 ls0 ws0">损失函数</div><div class="t m0 x29 h11 y45 ffa fs1 fc0 sc0 ls0 ws0"></div><div class="t m0 x20 h9 y44 ff6 fs1 fc0 sc0 ls0 ws0">可以量化模型的表现，评估模型输出结果</div><div class="t m0 x2a h11 y45 ffa fs1 fc0 sc0 ls0 ws0"></div><div class="t m0 x2b h9 y44 ff6 fs1 fc0 sc0 ls0 ws0">和真实标签</div><div class="t m0 x2c h11 y45 ffa fs1 fc0 sc0 ls0 ws0"></div><div class="t m0 x2d h9 y44 ff6 fs1 fc0 sc0 ls0 ws0">的差异程度。</div><div class="t m0 x0 hc y46 ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">交叉熵损失函式<span class="_ _5"> </span><span class="ff5">Cross-entropy<span class="_ _6"> </span>loss</span></span></div><div class="t m0 x0 h9 y47 ff6 fs1 fc0 sc0 ls0 ws0">在神经网络二元分类问题中，最常用的损失函数是交叉熵损失</div><div class="t m0 x2e h11 y48 ffa fs1 fc0 sc0 ls0 ws0"><span class="_ _0"> </span><span class="ff5">,<span class="_ _3"> </span></span></div><div class="t m0 x2f h9 y47 ff6 fs1 fc0 sc0 ls0 ws0">：</div><div class="t m0 x30 h14 y49 ffa fs5 fc0 sc0 ls0 ws0"></div><div class="t m0 x31 h14 y4a ffa fs5 fc0 sc0 ls0 ws0">,<span class="_ _3"></span></div><div class="t m0 x32 h14 y49 ffa fs5 fc0 sc0 ls0 ws0">=−<span class="_ _6"></span>[log<span class="_ _d"> </span> +</div><div class="t m0 x33 h14 y4a ffa fs5 fc0 sc0 ls0 ws0">1<span class="_ _6"></span>−<span class="_ _6"></span></div><div class="t m0 x2a h14 y49 ffa fs5 fc0 sc0 ls0 ws0">log</div><div class="t m0 x34 h14 y4a ffa fs5 fc0 sc0 ls0 ws0">1<span class="_ _1"></span>−<span class="_ _5"></span></div><div class="t m0 x35 h14 y49 ffa fs5 fc0 sc0 ls0 ws0">]</div></div><a class="l" href="https://github.com/HanXinzi-AI"><div class="d m1" style="border-style:none;position:absolute;left:195.750000px;bottom:513.550000px;width:27.000000px;height:14.650000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="http://show-me-ai.com/"><div class="d m1" style="border-style:none;position:absolute;left:230.650000px;bottom:513.550000px;width:47.400000px;height:14.650000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://stanford.edu/~shervine"><div class="d m1" style="border-style:none;position:absolute;left:449.950000px;bottom:513.550000px;width:124.650000px;height:14.650000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks"><div class="d m1" style="border-style:none;position:absolute;left:592.600000px;bottom:513.550000px;width:54.000000px;height:14.650000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf2" class="pf w0 h0" data-page-no="2"><div class="pc pc2 w0 h0"><img class="bi x0 y0 w5 h1" alt="" src="bg2.png"/><div class="t m0 x1 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">CS230<span class="_ _0"> </span><span class="ff2 fs1">|<span class="_ _1"> </span>Deep<span class="_ _3"> </span>Learning<span class="_ _1"> </span><span class="ff3">•<span class="_ _3"> </span></span>St<span class="_ _7"></span>anford<span class="_ _3"> </span>University<span class="_ _4"> </span><span class="ff4">系列内容 </span>Awesome<span class="_ _1"> </span>AI<span class="_ _3"> </span>Courses<span class="_ _1"> </span>Notes<span class="_ _3"> </span>Ch<span class="_ _7"></span>eat<span class="_ _3"> </span>Sh<span class="_ _7"></span>eets<span class="_ _3"> </span><span class="ff4">@<span class="_ _5"> </span></span>ShowMeAI</span></div><div class="t m0 x1 h3 y2 ff4 fs1 fc0 sc0 ls0 ws0">第三部分<span class="_ _6"> </span>深度学习技巧与建议<span class="_ _6"> </span>/</div><div class="t m0 x2 h4 y3 ff5 fs1 fc0 sc0 ls0 ws0">Deep<span class="_ _6"> </span>Lear<span class="_ _7"></span>ning<span class="_ _6"> </span>Tips<span class="_ _5"> </span>and<span class="_ _6"> </span>Tricks</div><div class="c x36 y4 w6 h5"><div class="t m0 x4 h6 y5 ff1 fs1 fc0 sc0 ls0 ws0">-<span class="_ _3"> </span>2<span class="_ _1"> </span>-</div></div><div class="c x4 y9 w3 h17"><div class="t m0 x1 h16 y4b ff5 fs7 fc0 sc0 ls0 ws0">2.2<span class="_ _5"> </span><span class="ff8">寻找<span class="_ _7"></span>最优权重<span class="_ _b"> </span></span>Finding<span class="_ _b"> </span>Optimal<span class="_ _5"> </span>W<span class="_ _7"></span>eights</div><div class="t m0 x1 hc y4c ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">反向传播<span class="_ _5"> </span><span class="ff5">Backpropagation</span></span></div><div class="t m0 x1 h9 y4d ff6 fs1 fc0 sc0 ls0 ws0">反向传播是一种通过考虑实际输出和期望输出来更新神经网络中权重的方法。使用链式</div><div class="t m0 x1 h9 y4e ff6 fs1 fc0 sc0 ls0 ws0">法则计算每个权重</div><div class="t m0 x37 h11 y4f ffa fs1 fc0 sc0 ls0 ws0">w</div><div class="t m0 x17 h9 y4e ff6 fs1 fc0 sc0 ls0 ws0">的导数。</div><div class="t m0 x1 h9 y50 ff6 fs1 fc0 sc0 ls0 ws0">反向传播中，每个权重都使用以下规则更新：</div><div class="t m0 x19 h14 y51 ffa fs5 fc0 sc0 ls0 ws0"><span class="_ _5"></span>←<span class="_ _5"></span><span class="_ _6"></span>−<span class="_ _6"></span></div><div class="t m0 x26 h14 y52 ffa fs5 fc0 sc0 ls0 ws0">∂</div><div class="t m0 x27 h14 y53 ffa fs5 fc0 sc0 ls0 ws0">,<span class="_ _3"></span></div><div class="t m0 x38 h14 y38 ffa fs5 fc0 sc0 ls0 ws0">∂</div><div class="t m0 x1 hc y54 ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">更新权重</span></div><div class="t m0 x39 h4 y55 ff5 fs1 fc0 sc0 ls0 ws0">Updating<span class="_ _6"> </span>wei<span class="_ _7"></span>ghts</div><div class="t m0 x1 h9 y56 ff6 fs1 fc0 sc0 ls0 ws0">在神经网络中，通过以下步骤更新权重：</div><div class="t m0 x1 h9 y57 ff8 fs1 fc0 sc0 ls0 ws0">步骤<span class="_ _7"></span>一<span class="_ _7"></span>：<span class="_ _7"></span><span class="ff6">取<span class="_ _7"></span>出<span class="_ _7"></span>一<span class="_ _7"></span>个批<span class="_ _7"></span>次<span class="_ _b"> </span><span class="ff5">(batch)<span class="_ _5"> </span></span>的资<span class="_ _7"></span>料<span class="_ _7"></span>，执<span class="_ _7"></span>行<span class="_ _7"></span>前<span class="_ _7"></span>向<span class="_ _7"></span>传<span class="_ _7"></span>播<span class="_ _7"></span>算<span class="_ _7"></span>法<span class="_ _5"> </span><span class="ff5">(<span class="_ _7"></span>forward<span class="_ _5"> </span>propagation)<span class="_ _5"> </span></span>来</span></div><div class="t m0 x1 h9 y58 ff6 fs1 fc0 sc0 ls0 ws0">得到对应的损失值。</div><div class="t m0 x1 h9 y59 ff8 fs1 fc0 sc0 ls0 ws0">步骤二：<span class="ff6">将损失值通过反向传播算法来得到梯度。</span></div><div class="t m0 x1 h9 y5a ff8 fs1 fc0 sc0 ls0 ws0">步骤三：<span class="ff6">使用梯度来更新网络的权重。</span></div><div class="t m0 x1 hb y5b ff2 fs0 fc0 sc0 ls0 ws0">[3]<span class="_ _6"> </span><span class="ff8">参数调优<span class="_ _5"> </span></span>/<span class="_ _6"> </span>Parameter<span class="_ _5"> </span>Tuning</div><div class="t m0 x1 h16 y5c ff5 fs7 fc0 sc0 ls0 ws0">3.1<span class="_ _5"> </span><span class="ff8">权重<span class="_ _7"></span>初始化<span class="_ _b"> </span></span>Weights<span class="_ _5"> </span>I<span class="_ _7"></span>nitialization</div><div class="t m0 x1 hc y5d ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">哈维尔初始化<span class="_ _5"> </span><span class="ff5">Xavier<span class="_ _6"> </span>initializatio<span class="_ _7"></span>n</span></span></div><div class="t m0 x1 h9 y5e ff5 fs8 fc0 sc0 ls0 ws0">Xavier<span class="_ _1"> </span><span class="ff6 fs1">初始化不是以纯粹随机方式初始化权重，而是使初始权重考虑到网络结构特征。</span></div></div><div class="c x6 y9 w3 h17"><div class="t m0 x0 hc y5f ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">迁移学习</span></div><div class="t m0 x16 h4 y60 ff5 fs1 fc0 sc0 ls0 ws0">Transfer<span class="_ _5"> </span>learning</div><div class="t m0 x0 h9 y61 ff6 fs1 fc0 sc0 ls0 ws0">训练深<span class="_ _7"></span>度<span class="_ _7"></span>学习<span class="_ _7"></span>模型<span class="_ _7"></span>需<span class="_ _7"></span>要大<span class="_ _7"></span>量数<span class="_ _7"></span>据，<span class="_ _7"></span>更重<span class="_ _7"></span>要的<span class="_ _7"></span>是<span class="_ _7"></span>需要<span class="_ _7"></span>大量<span class="_ _7"></span>时间<span class="_ _7"></span>。在<span class="_ _7"></span>需<span class="_ _7"></span>要数<span class="_ _7"></span>天</div><div class="t m0 x3a h4 y62 ff5 fs1 fc0 sc0 ls0 ws0">/</div><div class="t m0 x3b h9 y61 ff6 fs1 fc0 sc0 ls0 ws0">数周训<span class="_ _7"></span>练<span class="_ _7"></span>的</div><div class="t m0 x0 h9 y63 ff6 fs1 fc0 sc0 ls0 ws0">大型数据集上训练得到的预训练权重通常很有用，可以将其迁移应用于我们的场景。</div><div class="t m0 x0 h9 y64 ff6 fs1 fc0 sc0 ls0 ws0">根据我们手头的数据量多少，有不同的迁移学习方法：</div></div><div class="c x3c y65 w7 h18"><div class="t m0 x15 he y66 ff6 fs3 fc0 sc0 ls0 ws0">训练数据量</div></div><div class="c x3d y65 w8 h18"><div class="t m0 x3e he y66 ff6 fs3 fc0 sc0 ls0 ws0">图例</div></div><div class="c x3f y65 w9 h18"><div class="t m0 xa he y66 ff6 fs3 fc0 sc0 ls0 ws0">解释</div></div><div class="c x3c y67 w7 h19"><div class="t m0 x11 he y68 ff6 fs3 fc0 sc0 ls0 ws0">小数据量</div></div><div class="c x3f y67 w9 h19"><div class="t m0 x11 he y69 ff6 fs3 fc0 sc0 ls0 ws0">冻结所有其他<span class="_ _7"></span>层，在</div><div class="t m0 x11 he y6a ff5 fs3 fc0 sc0 ls0 ws0">softmax<span class="_ _1"> </span><span class="ff6">上训<span class="_ _7"></span>练权重</span></div></div><div class="c x3c y6b w7 h19"><div class="t m0 x15 he y6c ff6 fs3 fc0 sc0 ls0 ws0">中等数据量</div></div><div class="c x3f y6b w9 h19"><div class="t m0 x15 he y6d ff6 fs3 fc0 sc0 ls0 ws0">冻结大多数层<span class="_ _7"></span>，在最后</div><div class="t m0 x10 he y6c ff6 fs3 fc0 sc0 ls0 ws0">一层和<span class="_ _6"> </span><span class="ff5">softmax<span class="_ _1"> </span></span>上训</div><div class="t m0 x40 he y6e ff6 fs3 fc0 sc0 ls0 ws0">练权重</div></div><div class="c x3c y6f w7 h1a"><div class="t m0 x11 he y70 ff6 fs3 fc0 sc0 ls0 ws0">大数据量</div></div><div class="c x3f y6f w9 h1a"><div class="t m0 x15 he y71 ff6 fs3 fc0 sc0 ls0 ws0">通过预训练模<span class="_ _7"></span>型初始化</div><div class="t m0 x15 he y70 ff6 fs3 fc0 sc0 ls0 ws0">权重，训练所<span class="_ _7"></span>有的层次</div><div class="t m0 xe he y72 ff6 fs3 fc0 sc0 ls0 ws0">（包括 <span class="ff5">softmax<span class="_ _7"></span></span>）</div></div><div class="c x6 y9 w3 h17"><div class="t m0 x0 h16 y73 ff5 fs7 fc0 sc0 ls0 ws0">3.2<span class="_ _5"> </span><span class="ff8">优化<span class="_ _7"></span>与收敛细节<span class="_ _b"> </span></span>Optimizing<span class="_ _b"> </span>Convergence</div><div class="t m0 x0 hc y74 ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">学习率<span class="_ _5"> </span><span class="ff5">Learning<span class="_ _6"> </span>rate</span></span></div><div class="t m0 x0 h9 y75 ff6 fs1 fc0 sc0 ls0 ws0">学习率，通常记为</div><div class="t m0 x41 h11 y76 ffa fs1 fc0 sc0 ls0 ws0">α</div><div class="t m0 x42 h9 y75 ff6 fs1 fc0 sc0 ls0 ws0">，有时记作</div><div class="t m0 x2 h11 y76 ffa fs1 fc0 sc0 ls0 ws0">η</div><div class="t m0 x22 h9 y75 ff6 fs1 fc0 sc0 ls0 ws0">，表示权重更新的速度。它可以是固定的或<span class="_ _7"></span>自适应地</div><div class="t m0 x0 h9 y77 ff6 fs1 fc0 sc0 ls0 ws0">改变。目前最流行的方法叫做 <span class="ff5">Adam</span>，是一种自适应学习率的方法。</div><div class="t m0 x0 hc y78 ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">自适应学习率<span class="_ _5"> </span><span class="ff5">Adaptive<span class="_ _6"> </span>learning<span class="_ _5"> </span>rates</span></span></div><div class="t m0 x0 h9 y79 ff6 fs1 fc0 sc0 ls0 ws0">在训练模型时让学习率变化可以减少训练时间<span class="_ _7"></span>并提高数值最优解。<span class="ff5">Adam<span class="_ _5"> </span></span>优化器是最常</div><div class="t m0 x0 h9 y7a ff6 fs1 fc0 sc0 ls0 ws0">用的技术，但其他技术也很有用。</div><div class="t m0 x0 h9 y7b ff6 fs1 fc0 sc0 ls0 ws0">下表是对各种典型方法的一个总结：</div></div><div class="c x3c y7c wa h1b"><div class="t m0 xe hf y7d ff5 fs3 fc0 sc0 ls0 ws0">Method</div></div><div class="c x43 y7c wb h1b"><div class="t m0 xa hf y7d ff5 fs3 fc0 sc0 ls0 ws0">Explanation</div></div><div class="c x44 y7c w4 h1b"><div class="t m0 x45 h1c y7d ff5 fs3 fc0 sc0 ls0 ws0">Update<span class="_ _6"> </span>of<span class="_ _1"> </span><span class="ffa"></span></div></div><div class="c x46 y7c w4 h1b"><div class="t m0 x45 h1c y7d ff5 fs3 fc0 sc0 ls0 ws0">Update<span class="_ _6"> </span>of<span class="_ _1"> </span><span class="ffa"></span></div></div><div class="c x3c y7e wa h1d"><div class="t m0 x15 hf y7f ff5 fs3 fc0 sc0 ls0 ws0">Momentum</div></div><div class="c x43 y7e wb h1d"><div class="t m0 x45 he y80 ff6 fs3 fc0 sc0 ls0 ws0">抑制振荡，改进<span class="_ _6"> </span><span class="ff5">SGD</span></div><div class="t m0 x0 he y81 ff5 fs3 fc0 sc0 ls0 ws0">2<span class="_ _1"> </span><span class="ff6">个要调整<span class="_ _7"></span>的参数</span></div></div><div class="c x44 y7e w4 h1d"><div class="t m0 x0 h1c y82 ffa fs3 fc0 sc0 ls0 ws0"><span class="_ _3"></span>−<span class="_ _3"></span></div><div class="t m0 x47 h1c y83 ffa fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x48 h1e y84 ffa fs9 fc0 sc0 ls0 ws0"></div></div><div class="c x46 y7e w4 h1d"><div class="t m0 x1 h1c y83 ffa fs3 fc0 sc0 ls0 ws0"><span class="_ _3"></span>−<span class="_ _3"></span></div><div class="t m0 x48 h1e y84 ffa fs9 fc0 sc0 ls0 ws0"></div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf3" class="pf w0 h0" data-page-no="3"><div class="pc pc3 w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="bg3.png"/><div class="t m0 x1 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">CS230<span class="_ _0"> </span><span class="ff2 fs1">|<span class="_ _1"> </span>Deep<span class="_ _3"> </span>Learning<span class="_ _1"> </span><span class="ff3">•<span class="_ _3"> </span></span>St<span class="_ _7"></span>anford<span class="_ _3"> </span>University<span class="_ _4"> </span><span class="ff4">系列内容 </span>Awesome<span class="_ _1"> </span>AI<span class="_ _3"> </span>Courses<span class="_ _1"> </span>Notes<span class="_ _3"> </span>Ch<span class="_ _7"></span>eat<span class="_ _3"> </span>Sh<span class="_ _7"></span>eets<span class="_ _3"> </span><span class="ff4">@<span class="_ _5"> </span></span>ShowMeAI</span></div><div class="t m0 x1 h3 y2 ff4 fs1 fc0 sc0 ls0 ws0">第三部分<span class="_ _6"> </span>深度学习技巧与建议<span class="_ _6"> </span>/</div><div class="t m0 x2 h4 y3 ff5 fs1 fc0 sc0 ls0 ws0">Deep<span class="_ _6"> </span>Lear<span class="_ _7"></span>ning<span class="_ _6"> </span>Tips<span class="_ _5"> </span>and<span class="_ _6"> </span>Tricks</div><div class="c x36 y4 wc h5"><div class="t m0 x4 h6 y5 ff1 fs1 fc0 sc0 ls0 ws0">-<span class="_ _3"> </span>3<span class="_ _1"> </span>-</div></div><div class="c x0 y85 wa h1b"><div class="t m0 x49 hf y86 ff5 fs3 fc0 sc0 ls0 ws0">Method</div></div><div class="c x39 y85 wb h1b"><div class="t m0 xa hf y86 ff5 fs3 fc0 sc0 ls0 ws0">Explanation</div></div><div class="c x4a y85 w4 h1b"><div class="t m0 x45 h1c y86 ff5 fs3 fc0 sc0 ls0 ws0">Update<span class="_ _6"> </span>of<span class="_ _1"> </span><span class="ffa"></span></div></div><div class="c x35 y85 w4 h1b"><div class="t m0 x45 hf y86 ff5 fs3 fc0 sc0 ls0 ws0">Update<span class="_ _6"> </span>of</div><div class="t m0 x1e h1c y87 ffa fs3 fc0 sc0 ls0 ws0"></div></div><div class="c x0 y88 wa h1f"><div class="t m0 x4b hf y89 ff5 fs3 fc0 sc0 ls0 ws0">RMSprop</div></div><div class="c x39 y88 wb h1f"><div class="t m0 x4c he y8a ff6 fs3 fc0 sc0 ls0 ws0">均方根传播</div><div class="t m0 x4b he y8b ff6 fs3 fc0 sc0 ls0 ws0">通过控制振荡<span class="_ _7"></span>加速学习算法</div></div><div class="c x4a y88 w4 h1f"><div class="t m0 x12 h1c y8c ffa fs3 fc0 sc0 ls0 ws0"><span class="_ _3"></span>−<span class="_ _3"></span></div><div class="t m0 x4d h1c y8d ffa fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x48 h1c y8e ffa fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x1d h1e y8b ffa fs9 fc0 sc0 ls0 ws0"></div></div><div class="c x35 y88 w4 h1f"><div class="t m0 xd h1c y8c ffa fs3 fc0 sc0 ls0 ws0"><span class="_ _1"></span>←<span class="_ _6"></span><span class="_ _3"></span>−<span class="_ _3"></span></div><div class="t m0 x4e h1c y8d ffa fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x4f h1c y8e ffa fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x50 h1e y8b ffa fs9 fc0 sc0 ls0 ws0"></div></div><div class="c x0 y8f wa h20"><div class="t m0 x13 hf y90 ff5 fs3 fc0 sc0 ls0 ws0">Adam</div></div><div class="c x39 y8f wb h20"><div class="t m0 x10 he y91 ff6 fs3 fc0 sc0 ls0 ws0">自适应矩估计<span class="_ _7"></span>，最流<span class="_ _7"></span>行的方法</div><div class="t m0 x0 he y92 ff5 fs3 fc0 sc0 ls0 ws0">4<span class="_ _1"> </span><span class="ff6">个要调整<span class="_ _7"></span>的参数</span></div></div><div class="c x4a y8f w4 h20"><div class="t m0 x13 h1c y93 ffa fs3 fc0 sc0 ls0 ws0"><span class="_ _3"></span>−<span class="_ _3"></span></div><div class="t m0 x47 h1c y94 ffa fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x48 h1e y95 ffa fs9 fc0 sc0 ls0 ws0"></div><div class="t m0 x51 h1c y96 ffa fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x47 h1e y97 ffa fs9 fc0 sc0 ls0 ws0"></div><div class="t m0 x4e h1c y96 ffa fs3 fc0 sc0 ls0 ws0">+<span class="_ _3"></span></div></div><div class="c x35 y8f w4 h20"><div class="t m0 xe h1c y93 ffa fs3 fc0 sc0 ls0 ws0"><span class="_ _1"></span>←<span class="_ _1"></span><span class="_ _1"></span>−<span class="_ _3"></span></div><div class="t m0 x1d h1c y94 ffa fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x1e h1e y95 ffa fs9 fc0 sc0 ls0 ws0"></div><div class="t m0 x48 h1c y96 ffa fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x1d h1e y97 ffa fs9 fc0 sc0 ls0 ws0"></div><div class="t m0 x52 h1c y96 ffa fs3 fc0 sc0 ls0 ws0">+<span class="_ _3"></span></div></div><div class="c x4 y98 w3 h21"><div class="t m0 x1 h9 y99 ff6 fs1 fc0 sc0 ls0 ws0">备注：其他方法包括<span class="_ _6"> </span><span class="ff5">Adadelta</span>、<span class="ff5">Adagrad<span class="_ _5"> </span></span>和<span class="_ _6"> </span><span class="ff5">SGD</span>。</div><div class="t m0 x1 hb y9a ff2 fs0 fc0 sc0 ls0 ws0">[4]<span class="_ _6"> </span><span class="ff8">正则化<span class="_ _5"> </span></span>/<span class="_ _6"> </span>Regularization</div><div class="t m0 x1 hc y9b ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">随机失活<span class="_ _5"> </span><span class="ff5">Dropout</span></span></div><div class="t m0 x1 h9 y9c ff5 fs1 fc0 sc0 ls0 ws0">Dropout<span class="_ _5"> </span><span class="ff6">是神经网络中使<span class="_ _7"></span>用的一<span class="_ _7"></span>种技术，<span class="_ _7"></span>通过以<span class="_ _7"></span>概率</span></div><div class="t m0 x53 h11 y9d ffa fs1 fc0 sc0 ls0 ws0"><span class="_ _5"></span><span class="ff5">&gt;<span class="_ _6"> </span><span class="ffb">0</span></span></div><div class="t m0 x54 h9 y9c ff6 fs1 fc0 sc0 ls0 ws0">丢弃神经元<span class="_ _7"></span>来防止训<span class="_ _7"></span>练数据</div><div class="t m0 x1 h9 y9e ff6 fs1 fc0 sc0 ls0 ws0">过度拟合。它迫使模型避免过分依赖特定的特征集。</div><div class="t m0 x1 h9 y9f ff6 fs1 fc0 sc0 ls0 ws0">备注：大多数<span class="_ _7"></span>深度学习<span class="_ _7"></span>框架通过<span class="ff5">“<span class="_ _7"></span>keep”</span>参数来定<span class="_ _7"></span>义 <span class="ff5">dropout<span class="_ _5"> </span></span>程度，设<span class="_ _7"></span>定 <span class="ff5">keep<span class="_ _5"> </span></span>为</div><div class="t m0 x55 h11 ya0 ffa fs1 fc0 sc0 ls0 ws0">p</div><div class="t m0 x56 h9 y9f ff6 fs1 fc0 sc0 ls0 ws0">代</div><div class="t m0 x1 h9 ya1 ff6 fs1 fc0 sc0 ls0 ws0">表</div><div class="t m0 x28 h4 ya2 ff5 fs1 fc0 sc0 ls0 ws0">dropout</div><div class="t m0 x57 h9 ya1 ff6 fs1 fc0 sc0 ls0 ws0">为</div><div class="t m0 x3e h11 ya3 ffa fs1 fc0 sc0 ls0 ws0">1<span class="_ _1"></span>−<span class="_ _1"></span>p</div><div class="t m0 x58 h9 ya1 ff6 fs1 fc0 sc0 ls0 ws0">。</div><div class="t m0 x1 hc ya4 ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">权重正则化</span></div><div class="t m0 x3e h4 ya5 ff5 fs1 fc0 sc0 ls0 ws0">Weight<span class="_ _6"> </span>regul<span class="_ _7"></span>arization</div><div class="t m0 x1 h9 ya6 ff6 fs1 fc0 sc0 ls0 ws0">为确保权重不会太大且模型不会在训练集上过拟合，通常对模型权重应用正则化操作。</div></div><div class="c x0 ya7 wd h1b"><div class="t m0 x47 hf y7d ff5 fs3 fc0 sc0 ls0 ws0">LASSO</div></div><div class="c x32 ya7 we h1b"><div class="t m0 x4c hf y7d ff5 fs3 fc0 sc0 ls0 ws0">Ridge</div></div><div class="c x2a ya7 wf h1b"><div class="t m0 x4d hf y7d ff5 fs3 fc0 sc0 ls0 ws0">Elastic<span class="_ _6"> </span>Net</div></div><div class="c x0 ya8 wd h22"><div class="t m0 x10 he ya9 ff6 fs3 fc0 sc0 ls0 ws0">将系数缩小到<span class="_ _6"> </span><span class="ff5">0</span>，适合<span class="_ _7"></span>变量选</div><div class="t m0 x1d he yaa ff6 fs3 fc0 sc0 ls0 ws0">择</div></div><div class="c x32 ya8 we h22"><div class="t m0 x45 he yab ff6 fs3 fc0 sc0 ls0 ws0">获得更小的权<span class="_ _7"></span>重</div></div><div class="c x2a ya8 wf h22"><div class="t m0 x15 he ya9 ff6 fs3 fc0 sc0 ls0 ws0">变量选择和小<span class="_ _7"></span>权重系数之间<span class="_ _7"></span>的一个权</div><div class="t m0 x1f he yaa ff6 fs3 fc0 sc0 ls0 ws0">衡</div></div><div class="c x0 yac wd h23"><div class="t m0 x59 h1c yad ffa fs3 fc0 sc0 ls0 ws0">.<span class="_ _e"></span>.<span class="_ _e"></span>.<span class="_ _3"></span>+<span class="_ _1"></span>λ∣∣θ∣<span class="_ _7"></span>∣</div><div class="t m0 x20 h1e yae ffa fs9 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4d h1c yaf ffa fs3 fc0 sc0 ls0 ws0">λ<span class="_ _1"></span>∈<span class="_ _6"></span>ℝ</div></div><div class="c x32 yac we h23"><div class="t m0 x5a h1c yb0 ffa fs3 fc0 sc0 ls0 ws0">.<span class="_ _e"></span>.<span class="_ _e"></span>.<span class="_ _3"></span>+<span class="_ _1"></span>λ∣∣θ∣</div><div class="t m0 x50 h1c yad ffa fs3 fc0 sc0 ls0 ws0">∣</div><div class="t m0 x1f h1e yb1 ffa fs9 fc0 sc0 ls0 ws0">2</div><div class="t m0 x1f h1e yb2 ffa fs9 fc0 sc0 ls0 ws0">2</div><div class="t m0 x59 h1c yb3 ffa fs3 fc0 sc0 ls0 ws0">λ<span class="_ _1"></span>∈<span class="_ _6"></span>ℝ</div></div><div class="c x2a yac wf h23"><div class="t m0 xd h1c yb0 ffa fs3 fc0 sc0 ls0 ws0">.<span class="_ _e"></span>.<span class="_ _e"></span>.<span class="_ _3"></span>+<span class="_ _1"></span>λ<span class="_ _f"> </span>1<span class="_ _3"></span>−<span class="_ _3"></span>α<span class="_ _b"> </span>∣∣θ∣</div><div class="t m0 x5b h1c yad ffa fs3 fc0 sc0 ls0 ws0">∣</div><div class="t m0 x57 h1e yb4 ffa fs9 fc0 sc0 ls0 ws0">1</div><div class="t m0 x5c h1c yb0 ffa fs3 fc0 sc0 ls0 ws0">+<span class="_ _3"></span>α∣∣θ∣</div><div class="t m0 x5d h1c yad ffa fs3 fc0 sc0 ls0 ws0">∣</div><div class="t m0 x5e h1e yb1 ffa fs9 fc0 sc0 ls0 ws0">2</div><div class="t m0 x5e h1e yb2 ffa fs9 fc0 sc0 ls0 ws0">2</div><div class="t m0 x28 h1c yb3 ffa fs3 fc0 sc0 ls0 ws0">λ<span class="_ _1"></span>∈<span class="_ _6"></span>ℝ,<span class="_ _e"></span>α<span class="_ _1"></span>∈ 0,1</div></div><div class="c x6 y98 w3 h21"><div class="t m0 x0 hc yb5 ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">早停止</span></div><div class="t m0 x20 h4 yb6 ff5 fs1 fc0 sc0 ls0 ws0">Early<span class="_ _6"> </span>stopping</div><div class="t m0 x0 h9 yb7 ff6 fs1 fc0 sc0 ls0 ws0">早停止：一旦验证集上的损失不再降低或开始增加，就会停止训练过程。</div><div class="t m0 x0 hb yb8 ff2 fs0 fc0 sc0 ls0 ws0">[5]<span class="ff8">实践技巧<span class="_ _6"> </span></span>/<span class="_ _6"> </span>G<span class="_ _7"></span>ood<span class="_ _6"> </span>Practices</div><div class="t m0 x0 hc yb9 ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">小批量数据完全拟合测试<span class="_ _5"> </span><span class="ff5">Overfitting<span class="_ _6"> </span>small<span class="_ _5"> </span>batch</span></span></div><div class="t m0 x0 h9 yba ff6 fs1 fc0 sc0 ls0 ws0">在调试模型时，通常会快速测试以确保模型本身的结构没有重大问题。</div><div class="t m0 x0 h9 ybb ff6 fs1 fc0 sc0 ls0 ws0">具体<span class="_ _7"></span>说<span class="_ _7"></span>来<span class="_ _7"></span>，<span class="_ _7"></span>为<span class="_ _7"></span>了<span class="_ _7"></span>确保<span class="_ _7"></span>模<span class="_ _7"></span>型<span class="_ _7"></span>可<span class="_ _7"></span>以<span class="_ _7"></span>被<span class="_ _7"></span>正确<span class="_ _7"></span>训<span class="_ _7"></span>练<span class="_ _7"></span>，<span class="_ _7"></span>在<span class="_ _7"></span>网<span class="_ _7"></span>络<span class="_ _7"></span>内部<span class="_ _7"></span>传<span class="_ _7"></span>递<span class="_ _7"></span>了<span class="_ _7"></span>一<span class="_ _7"></span>个<span class="_ _5"> </span><span class="ff5">mini-batch<span class="_ _7"></span></span>，<span class="_ _7"></span>看<span class="_ _7"></span>看</div><div class="t m0 x0 h9 ybc ff6 fs1 fc0 sc0 ls0 ws0">它是否会过拟合</div><div class="t m0 x5f h4 ybd ff5 fs1 fc0 sc0 ls0 ws0">(</div><div class="t m0 x3e h9 ybc ff6 fs1 fc0 sc0 ls0 ws0">完全拟合</div><div class="t m0 x18 h4 ybd ff5 fs1 fc0 sc0 ls0 ws0">)</div><div class="t m0 x60 h9 ybc ff6 fs1 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h9 ybe ff6 fs1 fc0 sc0 ls0 ws0">如果不能，则意味着模型要么太复杂，要么不够复杂，以至于在小批量上都不能完全拟</div><div class="t m0 x0 h9 ybf ff6 fs1 fc0 sc0 ls0 ws0">合，更不用说正常大小的训练集了。</div><div class="t m0 x0 hc yc0 ff9 fs1 fc0 sc0 ls0 ws0">░▐<span class="_ _6"> </span><span class="ff8">梯度检查<span class="_ _5"> </span><span class="ff5">Gradient<span class="_ _6"> </span>checking</span></span></div><div class="t m0 x0 h9 yc1 ff6 fs1 fc0 sc0 ls0 ws0">梯度检查是在实现神经网络的反向传递过程中使用的一种方法。具体的做法是，将分析</div><div class="t m0 x0 h9 yc2 ff6 fs1 fc0 sc0 ls0 ws0">梯度的值与给定点的数值梯度进行比较，检查其正确性。</div></div><div class="c x3c yc3 w10 h24"><div class="t m0 x15 he yc4 ff6 fs3 fc0 sc0 ls0 ws0">类型</div></div><div class="c x61 yc3 w11 h24"><div class="t m0 x62 he yc4 ff6 fs3 fc0 sc0 ls0 ws0">数值梯度</div></div><div class="c x63 yc3 w12 h24"><div class="t m0 x45 he yc4 ff6 fs3 fc0 sc0 ls0 ws0">解析梯度</div></div><div class="c x3c yc5 w10 h25"><div class="t m0 x15 he yc6 ff6 fs3 fc0 sc0 ls0 ws0">公式</div></div><div class="c x61 yc5 w11 h25"><div class="t m0 x64 h11 yc7 ffa fs1 fc0 sc0 ls0 ws0">df</div><div class="t m0 x64 h11 yc8 ffa fs1 fc0 sc0 ls0 ws0">dx</div><div class="t m0 x16 h11 yc9 ffa fs1 fc0 sc0 ls0 ws0">x<span class="_ _10"> </span>≈</div><div class="t m0 x41 h11 yc7 ffa fs1 fc0 sc0 ls0 ws0">f<span class="_ _0"> </span>x<span class="_ _1"></span>+<span class="_ _1"></span>h −<span class="_ _1"></span>f<span class="_ _8"> </span>x<span class="_ _1"></span>−<span class="_ _1"></span>h</div><div class="t m0 x60 h11 yc8 ffa fs1 fc0 sc0 ls0 ws0">2h</div></div><div class="c x63 yc5 w12 h25"><div class="t m0 xe h11 yca ffa fs1 fc0 sc0 ls0 ws0">df</div><div class="t m0 x4b h11 ycb ffa fs1 fc0 sc0 ls0 ws0">dx</div><div class="t m0 x12 h11 ycc ffa fs1 fc0 sc0 ls0 ws0">x<span class="_ _10"> </span>=<span class="_ _6"></span>f<span class="_ _7"></span>′<span class="_ _0"> </span>x</div></div><div class="c x3c ycd w10 h26"><div class="t m0 x15 he yce ff6 fs3 fc0 sc0 ls0 ws0">注解</div></div><div class="c x61 ycd w11 h26"><div class="t m0 x48 he ycf ff6 fs3 fc0 sc0 ls0 ws0">计算代价高；<span class="_ _7"></span>每个维度必须<span class="_ _7"></span>计算两次<span class="_ _7"></span>损失</div><div class="t m0 x65 he yce ff6 fs3 fc0 sc0 ls0 ws0">用于验证分析<span class="_ _7"></span>实现的正确性</div><div class="t m0 x15 he yd0 ff6 fs3 fc0 sc0 ls0 ws0">权衡选择</div><div class="t m0 x4c h1c yd1 ffa fs3 fc0 sc0 ls0 ws0">ℎ</div><div class="t m0 x51 he yd0 ff6 fs3 fc0 sc0 ls0 ws0">既不能太小（<span class="_ _7"></span>数值不稳定性<span class="_ _7"></span>）也不能<span class="_ _7"></span>太大（计算精<span class="_ _7"></span>度差）</div></div><div class="c x63 ycd w12 h26"><div class="t m0 xd he ycf ff6 fs3 fc0 sc0 ls0 ws0">结果<span class="ff5">“</span>精确<span class="ff5">”</span></div><div class="t m0 x15 he yce ff6 fs3 fc0 sc0 ls0 ws0">解析公式直接<span class="_ _7"></span>计算</div><div class="t m0 x15 he yd0 ff6 fs3 fc0 sc0 ls0 ws0">最终实现中会<span class="_ _7"></span>使用</div></div><div class="c x6 y98 w3 h21"><div class="t m0 x66 h14 yd2 ffa fs5 fc0 sc0 ls0 ws0"></div><div class="t m0 x66 h14 yd3 ffa fs5 fc0 sc0 ls0 ws0"></div><div class="t m0 x67 h14 yd4 ffa fs5 fc0 sc0 ls0 ws0"><span class="_ _11"> </span>≈</div><div class="t m0 x1c h14 yd5 ffa fs5 fc0 sc0 ls0 ws0"><span class="_ _8"> </span><span class="_ _6"></span>+<span class="_ _6"></span>ℎ −<span class="_ _1"></span><span class="_ _12"> </span><span class="_ _6"></span>−<span class="_ _6"></span>ℎ</div><div class="t m0 x68 h14 yd3 ffa fs5 fc0 sc0 ls0 ws0">2ℎ</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf4" class="pf w0 h0" data-page-no="4"><div class="pc pc4 w0 h0"><img class="bi x0 y0 w13 h1" alt="" src="bg4.png"/><div class="t m0 x1 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">CS230<span class="_ _0"> </span><span class="ff2 fs1">|<span class="_ _1"> </span>Deep<span class="_ _3"> </span>Learning<span class="_ _1"> </span><span class="ff3">•<span class="_ _3"> </span></span>St<span class="_ _7"></span>anford<span class="_ _3"> </span>University<span class="_ _4"> </span><span class="ff4">系列内容 </span>Awesome<span class="_ _1"> </span>AI<span class="_ _3"> </span>Courses<span class="_ _1"> </span>Notes<span class="_ _3"> </span>Ch<span class="_ _7"></span>eat<span class="_ _3"> </span>Sh<span class="_ _7"></span>eets<span class="_ _3"> </span><span class="ff4">@<span class="_ _5"> </span></span>ShowMeAI</span></div><div class="t m0 x1 h3 y2 ff4 fs1 fc0 sc0 ls0 ws0">第三部分<span class="_ _6"> </span>深度学习技巧与建议<span class="_ _6"> </span>/</div><div class="t m0 x2 h4 y3 ff5 fs1 fc0 sc0 ls0 ws0">Deep<span class="_ _6"> </span>Lear<span class="_ _7"></span>ning<span class="_ _6"> </span>Tips<span class="_ _5"> </span>and<span class="_ _6"> </span>Tricks</div><div class="c x36 y4 w14 h5"><div class="t m0 x4 h6 y5 ff1 fs1 fc0 sc0 ls0 ws0">-<span class="_ _3"> </span>4<span class="_ _3"> </span>-</div></div><div class="t m0 x1 h27 yd6 ff2 fsa fc0 sc0 ls0 ws0">Awesome<span class="_ _5"> </span>AI<span class="_ _5"> </span>Courses<span class="_ _5"> </span>Notes<span class="_ _5"> </span>C<span class="_ _7"></span>heat<span class="_ _5"> </span>Sheets</div><div class="c x0 yd7 w15 h28"><div class="t m0 x15 h29 y8a ff2 fs5 fc0 sc0 ls0 ws0">Machine<span class="_ _1"> </span>Learni<span class="_ _7"></span>ng</div><div class="t m0 x15 h2a yd8 ff1 fs5 fc0 sc0 ls0 ws0">CS229</div></div><div class="c x69 yd7 w16 h28"><div class="t m0 x15 h29 y8a ff2 fs5 fc0 sc0 ls0 ws0">Deep<span class="_ _1"> </span>Le<span class="_ _7"></span>arning</div><div class="t m0 x15 h2a yd8 ff1 fs5 fc0 sc0 ls0 ws0">CS230</div></div><div class="c xb yd7 w17 h28"><div class="t m0 x15 h2b y8d ffc fs1 fc0 sc0 ls0 ws0">Natural<span class="_ _3"> </span>Language<span class="_ _1"> </span>Processing</div><div class="t m0 x15 h2c yd9 ffd fs1 fc0 sc0 ls0 ws0">CS224n</div></div><div class="c x3b yd7 w18 h28"><div class="t m0 x15 h2b y8d ffc fs1 fc0 sc0 ls0 ws0">Computer<span class="_ _3"> </span>Vi<span class="_ _7"></span>sion</div><div class="t m0 x15 h2c yd9 ffd fs1 fc0 sc0 ls0 ws0">CS231n</div></div><div class="c x6a yd7 w19 h28"><div class="t m0 x15 h2b y8d ffc fs1 fc0 sc0 ls0 ws0">Deep<span class="_ _3"> </span>Reinforcement<span class="_ _1"> </span>Learning</div><div class="t m0 x15 h2c yd9 ffd fs1 fc0 sc0 ls0 ws0">CS285</div></div><div class="c x6b yd7 w1a h28"><div class="t m0 x15 h2b y8d ffc fs1 fc0 sc0 ls0 ws0">Neural<span class="_ _3"> </span>Networks<span class="_ _1"> </span>for<span class="_ _3"> </span>NLP</div><div class="t m0 x15 h2c yd9 ffd fs1 fc0 sc0 ls0 ws0">CS11-747</div></div><div class="c x6c yd7 w1b h28"><div class="t m0 x15 h2b y8d ffc fs1 fc0 sc0 ls0 ws0">DL<span class="_ _3"> </span>for<span class="_ _1"> </span>Self-Driving<span class="_ _3"> </span>Cars</div><div class="t m0 x15 h2c yd9 ffd fs1 fc0 sc0 ls0 ws0">6.S094</div></div><div class="c x6d yd7 w1c h28"><div class="t m0 x4b h6 yda ff1 fs1 fc0 sc0 ls0 ws0">...</div></div><div class="c x0 ydb w15 h2d"><div class="t m0 x15 h2e ydc ffe fs1 fc0 sc0 ls0 ws0">Stanford</div></div><div class="c x69 ydb w16 h2d"><div class="t m0 x15 h2e ydc ffe fs1 fc0 sc0 ls0 ws0">Stanford</div></div><div class="c xb ydb w17 h2d"><div class="t m0 x15 h2e ydc ffe fs1 fc0 sc0 ls0 ws0">Stanford</div></div><div class="c x3b ydb w18 h2d"><div class="t m0 x15 h2e ydc ffe fs1 fc0 sc0 ls0 ws0">Stanford</div></div><div class="c x6a ydb w19 h2d"><div class="t m0 x15 h2e ydc ffe fs1 fc0 sc0 ls0 ws0">UC<span class="_ _1"> </span>Berkeley</div></div><div class="c x6b ydb w1a h2d"><div class="t m0 x15 h2e ydc ffe fs1 fc0 sc0 ls0 ws0">CMU</div></div><div class="c x6c ydb w1b h2d"><div class="t m0 x15 h2e ydc ffe fs1 fc0 sc0 ls0 ws0">MIT</div></div><div class="c x6d ydb w1c h2d"><div class="t m0 x4b h6 ydd ff1 fs1 fc0 sc0 ls0 ws0">...</div></div><div class="c x4 yde w1d h2f"><div class="t m0 x1 h14 ydf ff6 fs5 fc0 sc0 ls0 ws0">是 <span class="ff7">ShowM<span class="_ _7"></span>eAI<span class="_ _6"> </span></span>资<span class="_ _7"></span>料<span class="_ _c"></span>库<span class="_ _7"></span>的<span class="_ _7"></span>分<span class="_ _7"></span>支<span class="_ _7"></span>系<span class="_ _7"></span>列<span class="_ _7"></span>，<span class="_ _7"></span>覆<span class="_ _7"></span>盖<span class="_ _7"></span>最<span class="_ _7"></span>具<span class="_ _c"></span>知名<span class="_ _7"></span>度<span class="_ _7"></span>的<span class="_ _13"> </span><span class="ffa">TOP20+<span class="_ _7"></span></span>门<span class="_ _13"> </span><span class="ff7">AI<span class="_ _5"> </span></span>课<span class="_ _7"></span>程<span class="_ _7"></span>，<span class="_ _7"></span>旨<span class="_ _7"></span>在<span class="_ _7"></span>为<span class="_ _c"></span>读者<span class="_ _7"></span>和</div><div class="t m0 x1 h30 ye0 ff6 fs5 fc0 sc0 ls0 ws0">学习者提供<span class="_ _7"></span>一整套高品质<span class="_ _7"></span>中文速查表，<span class="_ _7"></span>可以点<span class="_ _7"></span>击【这里】<span class="_ _7"></span>查看。</div><div class="t m0 x1 h30 ye1 ff6 fs5 fc0 sc0 ls0 ws0">斯<span class="_ _3"> </span>坦<span class="_ _3"> </span>福<span class="_ _3"> </span>大<span class="_ _3"> </span>学<span class="_ _3"> </span>（<span class="_ _3"> </span><span class="ff7">St<span class="_ _2"></span>anford<span class="_ _0"> </span>Un<span class="_ _7"></span>iversity<span class="_ _3"> </span><span class="ff6">）<span class="_ _3"> </span>的<span class="_ _14"> </span></span>Machine<span class="_ _0"> </span>Learn<span class="_ _7"></span>ing<span class="_ _3"> </span><span class="ff6">（<span class="_ _3"> </span></span>CS229<span class="_ _3"> </span><span class="ff6">）<span class="_ _3"> </span>和<span class="_ _14"> </span></span>Deep<span class="_ _0"> </span>Learning</span></div><div class="t m0 x1 h30 ye2 ff6 fs5 fc0 sc0 ls0 ws0">（<span class="ff7">CS230</span>）课<span class="_ _7"></span>程，是本系列<span class="_ _7"></span>的第一批<span class="_ _7"></span>产出。</div></div><div class="c x6e yde w1e h2f"><div class="t m0 x4b h30 ydf ff6 fs5 fc0 sc0 ls0 ws0">本<span class="_ _7"></span>批<span class="_ _7"></span>两<span class="_ _7"></span>门<span class="_ _c"></span>课<span class="_ _7"></span>程<span class="_ _c"></span>的<span class="_ _7"></span>速<span class="_ _7"></span>查<span class="_ _7"></span>表<span class="_ _c"></span>由<span class="_ _7"></span>斯<span class="_ _7"></span>坦<span class="_ _7"></span>福<span class="_ _c"></span>大<span class="_ _7"></span>学<span class="_ _c"></span>计<span class="_ _7"></span>算<span class="_ _7"></span>机<span class="_ _7"></span>专<span class="_ _c"></span>业<span class="_ _7"></span>学<span class="_ _c"></span>生<span class="_ _5"> </span><span class="ff7">Shervine<span class="_ _6"> </span>Amidi<span class="_ _b"> </span></span>总</div><div class="t m0 x4b h30 ye0 ff6 fs5 fc0 sc0 ls0 ws0">结整理<span class="_ _7"></span>。原速查<span class="_ _7"></span>表为英文<span class="_ _7"></span>，可点击<span class="_ _7"></span>【这里】查<span class="_ _7"></span>看</div><div class="t m0 x27 h31 ye3 fff fs5 fc0 sc0 ls0 ws0">，<span class="ff7">ShowMeAI</span></div><div class="t m0 x6f h30 ye0 ff6 fs5 fc0 sc0 ls0 ws0">对内容<span class="_ _7"></span>进行</div><div class="t m0 x4b h30 ye4 ff6 fs5 fc0 sc0 ls0 ws0">了翻译、校<span class="_ _7"></span>对与编辑排版<span class="_ _7"></span>，整理为当前<span class="_ _7"></span>的中文<span class="_ _7"></span>版本。</div><div class="t m0 x4b h30 ye2 ff6 fs5 fc0 sc0 ls0 ws0">有任何建议<span class="_ _7"></span>和反馈，也欢<span class="_ _7"></span>迎通过下方渠<span class="_ _7"></span>道和我<span class="_ _7"></span>们联络<span class="_ _5"> </span><span class="ff5">(*</span>￣<span class="ff5">3</span>￣<span class="ff5">)</span></div></div><div class="c x0 ye5 w1f h32"><div class="t m0 x15 h33 ye6 ff1 fsa fc0 sc0 ls0 ws0">CS229<span class="_ _1"> </span><span class="ff7 fsb">|<span class="_ _6"> </span><span class="ff2 fs7">Machine<span class="_ _6"> </span>Learning<span class="_ _6"> </span>@<span class="_ _6"> </span>Stanford<span class="_ _6"> </span>University</span></span></div></div><div class="c x70 ye5 w20 h32"><div class="t m0 x15 h33 ye6 ff1 fsa fc0 sc0 ls0 ws0">CS230<span class="_ _1"> </span><span class="ff7 fsb">|<span class="_ _6"> </span><span class="ff2 fs7">Deep<span class="_ _d"> </span>Learning<span class="_ _6"> </span>@<span class="_ _6"> </span>Stanford<span class="_ _6"> </span>University</span></span></div></div><div class="c x0 ye7 w1b h34"><div class="t m0 x5a h35 ye8 ff4 fs5 fc0 sc0 ls0 ws0">监督学习</div><div class="t m0 x4b h2b ye9 ffc fs1 fc0 sc0 ls0 ws0">Supervised<span class="_ _3"> </span>Learning</div></div><div class="c x71 ye7 w1b h34"><div class="t m0 xf h35 ye8 ff4 fs5 fc0 sc0 ls0 ws0">无监督学习</div><div class="t m0 x15 h2b ye9 ffc fs1 fc0 sc0 ls0 ws0">Unsupervised<span class="_ _3"> </span>Learning</div></div><div class="c x72 ye7 w1b h34"><div class="t m0 x5a h35 ye8 ff4 fs5 fc0 sc0 ls0 ws0">深度学习</div><div class="t m0 x45 h2b ye9 ffc fs1 fc0 sc0 ls0 ws0">Deep<span class="_ _3"> </span>Learning</div></div><div class="c x73 ye7 w21 h34"><div class="t m0 x15 h35 ye8 ff4 fs5 fc0 sc0 ls0 ws0">机器学习技<span class="_ _7"></span>巧和经验</div><div class="t m0 xf h2b ye9 ffc fs1 fc0 sc0 ls0 ws0">Tips<span class="_ _3"> </span>and<span class="_ _1"> </span>Tricks</div></div><div class="c x70 ye7 w22 h34"><div class="t m0 x45 h35 ye8 ff4 fs5 fc0 sc0 ls0 ws0">卷积神经网<span class="_ _7"></span>络</div><div class="t m0 x51 h2b ye9 ffc fs1 fc0 sc0 ls0 ws0">CNN</div></div><div class="c x74 ye7 w23 h34"><div class="t m0 x45 h35 ye8 ff4 fs5 fc0 sc0 ls0 ws0">循环神经网<span class="_ _7"></span>络</div><div class="t m0 x51 h2b ye9 ffc fs1 fc0 sc0 ls0 ws0">RNN</div></div><div class="c x75 ye7 w24 h34"><div class="t m0 x10 h35 ye8 ff4 fs5 fc0 sc0 ls0 ws0">深度学习技<span class="_ _7"></span>巧与建议</div><div class="t m0 x0 h2b ye9 ffc fs1 fc0 sc0 ls0 ws0">Tips<span class="_ _3"> </span>and<span class="_ _1"> </span>Tricks</div></div><div class="c x0 yea w1b h36"><div class="t m0 xd h3 yeb ff4 fs1 fc0 sc0 ls0 ws0">中文速查表链接</div></div><div class="c x71 yea w1b h36"><div class="t m0 xd h3 yeb ff4 fs1 fc0 sc0 ls0 ws0">中文速查表链接</div></div><div class="c x72 yea w1b h36"><div class="t m0 xd h3 yeb ff4 fs1 fc0 sc0 ls0 ws0">中文速查表链接</div></div><div class="c x73 yea w21 h36"><div class="t m0 xd h3 yeb ff4 fs1 fc0 sc0 ls0 ws0">中文速查表链接</div></div><div class="c x70 yea w22 h36"><div class="t m0 x45 h3 yeb ff4 fs1 fc0 sc0 ls0 ws0">中文速查表链接</div></div><div class="c x74 yea w23 h36"><div class="t m0 x45 h3 yeb ff4 fs1 fc0 sc0 ls0 ws0">中文速查表链接</div></div><div class="c x75 yea w24 h36"><div class="t m0 xf h3 yeb ff4 fs1 fc0 sc0 ls0 ws0">中文速查表链接</div></div><div class="c x0 yec w1b h34"><div class="t m0 x5a h35 yed ff4 fs5 fc0 sc0 ls0 ws0">概率统计</div><div class="t m0 x15 h2b yee ffc fs1 fc0 sc0 ls0 ws0">Probabilities<span class="_ _3"> </span>/Statistics</div></div><div class="c x71 yec w25 h34"><div class="t m0 x13 h35 yed ff4 fs5 fc0 sc0 ls0 ws0">线性代数与<span class="_ _7"></span>微积分</div><div class="t m0 x15 h2b yee ffc fs1 fc0 sc0 ls0 ws0">Linear<span class="_ _3"> </span>Algebra<span class="_ _1"> </span>and<span class="_ _3"> </span>Calculus</div></div><div class="c x76 yef w26 h37"><div class="t m0 xf h38 yf0 ff1 fsc fc0 sc0 ls0 ws0">GitHub</div><div class="t m0 xf h39 yf1 ff7 fs5 fc0 sc0 ls0 ws0">ShowMeAI</div><div class="t m0 x15 h3a yf2 ff7 fs1 fc0 sc0 ls0 ws0">https://github.com/</div><div class="t m0 x14 h3a yf3 ff7 fs1 fc0 sc0 ls0 ws0">ShowMeAI-Hub/</div></div><div class="c x75 yef w27 h37"><div class="t m0 x15 h35 yf4 ff4 fs5 fc0 sc0 ls0 ws0">ShowMeAI<span class="_ _5"> </span>研究中心</div><div class="t m0 x15 h11 yf5 ff6 fs1 fc0 sc0 ls0 ws0">扫码回复<span class="ffa">”</span></div><div class="t m0 x77 h3b yf6 ff4 fs7 fc0 sc0 ls0 ws0">速查表</div><div class="t m0 x5b h11 yf5 ffa fs1 fc0 sc0 ls0 ws0">”</div><div class="t m0 x15 h9 yf7 ff6 fs1 fc0 sc0 ls0 ws0">下载</div><div class="t m0 xf h3b yf8 ff4 fs7 fc0 sc0 ls0 ws0">最新</div><div class="t m0 x51 h9 yf7 ff6 fs1 fc0 sc0 ls0 ws0">全套资料</div></div><div class="c x0 yf9 w1b h3c"><div class="t m0 xd h3 yfa ff4 fs1 fc0 sc0 ls0 ws0">中文速查表链接</div></div><div class="c x71 yf9 w1b h3c"><div class="t m0 xd h3 yfa ff4 fs1 fc0 sc0 ls0 ws0">中文速查表链接</div></div><a class="l" href="http://show-me-ai.com/"><div class="d m1" style="border-style:none;position:absolute;left:43.500000px;bottom:459.950000px;width:47.600000px;height:16.250000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://github.com/ShowMeAI-Hub/"><div class="d m1" style="border-style:none;position:absolute;left:248.350000px;bottom:443.700000px;width:20.000000px;height:16.250000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://stanford.edu/~shervine/"><div class="d m1" style="border-style:none;position:absolute;left:682.750000px;bottom:459.950000px;width:68.250000px;height:16.250000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://stanford.edu/~shervine/teaching/cs-230/"><div class="d m1" style="border-style:none;position:absolute;left:606.250000px;bottom:443.700000px;width:20.050000px;height:16.250000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://github.com/ShowMeAI-Hub/awesome-AI-courses-notes-cheatsheets/tree/main/CS229-Machine-Learning/Supervised-Learning"><div class="d m1" style="border-style:none;position:absolute;left:44.550000px;bottom:227.850000px;width:67.500000px;height:14.650000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://github.com/ShowMeAI-Hub/awesome-AI-courses-notes-cheatsheets/tree/main/CS229-Machine-Learning/Unsupervised-Learning"><div class="d m1" style="border-style:none;position:absolute;left:143.750000px;bottom:227.850000px;width:67.500000px;height:14.650000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://github.com/ShowMeAI-Hub/awesome-AI-courses-notes-cheatsheets/tree/main/CS229-Machine-Learning/Deep-Learning"><div class="d m1" style="border-style:none;position:absolute;left:242.950000px;bottom:227.850000px;width:67.500000px;height:14.650000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://github.com/ShowMeAI-Hub/awesome-AI-courses-notes-cheatsheets/tree/main/CS229-Machine-Learning/Machine-Learning-tips-and-tricks"><div class="d m1" style="border-style:none;position:absolute;left:343.600000px;bottom:227.850000px;width:67.500000px;height:14.650000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://github.com/ShowMeAI-Hub/awesome-AI-courses-notes-cheatsheets/tree/main/CS230-Deep-Learning/Convolutional-Neural-Networks"><div class="d m1" style="border-style:none;position:absolute;left:464.500000px;bottom:227.850000px;width:67.500000px;height:14.650000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://github.com/ShowMeAI-Hub/awesome-AI-courses-notes-cheatsheets/tree/main/CS230-Deep-Learning/Recurrent-Neural-Networks"><div class="d m1" style="border-style:none;position:absolute;left:568.900000px;bottom:227.850000px;width:67.500000px;height:14.650000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://github.com/ShowMeAI-Hub/awesome-AI-courses-notes-cheatsheets/tree/main/CS230-Deep-Learning/Deep-Learning-Tips-and-Tricks"><div class="d m1" style="border-style:none;position:absolute;left:675.800000px;bottom:227.850000px;width:67.500000px;height:14.650000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://github.com/ShowMeAI-Hub/"><div class="d m1" style="border-style:none;position:absolute;left:462.650000px;bottom:119.200000px;width:79.750000px;height:10.800000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://github.com/ShowMeAI-Hub/"><div class="d m1" style="border-style:none;position:absolute;left:462.650000px;bottom:119.200000px;width:79.750000px;height:10.800000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://github.com/ShowMeAI-Hub/awesome-AI-courses-notes-cheatsheets/tree/main/Probabilities-and-Statistics"><div class="d m1" style="border-style:none;position:absolute;left:44.550000px;bottom:71.950000px;width:67.500000px;height:14.650000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="https://github.com/ShowMeAI-Hub/awesome-AI-courses-notes-cheatsheets/tree/main/Linear-Algebra-and-Calculus"><div class="d m1" style="border-style:none;position:absolute;left:143.750000px;bottom:71.950000px;width:67.500000px;height:14.650000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
</div>
<div class="loading-indicator">
<img alt="" src="pdf2htmlEX-64x64.png"/>
</div>
</body>
</html>
